seed_everything: true
trainer:
  accelerator: gpu
  strategy: ddp_find_unused_parameters_true
  devices: [4,5,6,7]
  num_nodes: 1
  precision: 32
  max_epochs: 50
  check_val_every_n_epoch: 1
  num_sanity_val_steps: 0
  log_every_n_steps: 100
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: "vq_audio_simvq_bert_mel_avg/8k_ration_20_loss" # Please specify your own path
        save_top_k: -1 # save all checkpoints
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
  logger:
    class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      save_dir: "vq_audio_simvq_bert_mel_avg/8k_ration_20_loss" #Please specify your own path
      version: "1second"
      name: "tmp"

model:
  class_path: taming.models.simvq_gan_hubert.VQModel
  init_args:
    ddconfig:
      causal: true
      dimension: 512
      ratios: [8,8,4,4]
    
    lossconfig:
      target: taming.modules.losses.stft_simvq_mel.VQSTFTWithDiscriminator
      params:
          cqtd_filters: 128,
          cqtd_max_filters: 1024,
          cqtd_filters_scale: 1,
          cqtd_dilations: [1, 2, 4],
          cqtd_hop_lengths: [512, 256, 256],
          cqtd_n_octaves: [9, 9, 9],
          cqtd_bins_per_octaves: [24, 36, 48],
    
    sample_rate: 24000
    audio_normalize: false
    segment: None
    learning_rate: 1e-4
    scheduler_type: "None"
    use_ema: true

data:
  class_path: taming.data.speechdataset.SpeechTokenizerDataModule
  init_args:
    batch_size: 6
    num_workers: 8
    train_metalst : "/root/Github/TTS_Tokenizer/data/train_small.txt"
    val_metalst : "/root/Github/TTS_Tokenizer/data/test_1500.txt"
    segement_size: 65536

ckpt_path: null
